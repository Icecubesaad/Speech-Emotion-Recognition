{"cells":[{"cell_type":"markdown","metadata":{"id":"Qi13Xt2QOwEw"},"source":["# Dataset"]},{"cell_type":"markdown","metadata":{"id":"F_Vja81uPFfl"},"source":["# Importing libraries"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":439,"status":"ok","timestamp":1728592277382,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"emqQ13VLPH25"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","import os\n","import sys\n","\n","# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n","import librosa\n","import librosa.display\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.metrics import confusion_matrix, classification_report\n","from sklearn.model_selection import train_test_split\n","\n","# to play the audio files\n","from IPython.display import Audio\n","\n","import keras\n","from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n","from tensorflow.keras.utils import to_categorical\n","from keras.callbacks import ModelCheckpoint\n","from tensorflow.python.keras.layers.recurrent import LSTM\n","\n","import warnings\n","if not sys.warnoptions:\n","    warnings.simplefilter(\"ignore\")\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"]},{"cell_type":"markdown","metadata":{"id":"qhuDaFM1P3pp"},"source":["# Dataset Preparation"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":499,"status":"ok","timestamp":1728576445328,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"pgsfRRF3HoZY"},"outputs":[],"source":["# Paths for data.\n","Ravdess = \"../dataset/Ravdess/audio_speech_actors_01-24/\"\n","Crema = \"../dataset/Crema/\"\n","Tess = \"../dataset/Tess/\"\n","Savee = \"../dataset/Savee/\""]},{"cell_type":"markdown","metadata":{"id":"NK1P_XMsJANa"},"source":["# Ravdees"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":347},"executionInfo":{"elapsed":461,"status":"ok","timestamp":1728576982254,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"Jr70KgVYInmP","outputId":"ab015d27-d682-41e0-96bb-e090fa2ead1c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotions</th>\n","      <th>Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>happy</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>happy</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>neutral</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>disgust</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fear</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>sad</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>fear</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>surprise</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>neutral</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>calm</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Emotions                                               Path\n","0     happy  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","1     happy  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","2   neutral  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","3   disgust  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","4      fear  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","5       sad  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","6      fear  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","7  surprise  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","8   neutral  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","9      calm  ../dataset/Ravdess/audio_speech_actors_01-24/A..."]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["ravdess_directory_list = os.listdir(Ravdess)\n","\n","file_emotion = []\n","file_path = []\n","for dir in ravdess_directory_list:\n","    # as their are 24 different actors in our previous directory we need to extract files for each actor.\n","    actor = os.listdir(Ravdess + dir)\n","    for file in actor:\n","        part = file.split('.')[0]\n","        part = part.split('-')\n","        # third number in each file represents the emotion associated to that file.\n","        file_emotion.append(int(part[2]))\n","        # storing the path of the file\n","        file_path.append(Ravdess + dir + '/' + file)\n","\n","# dataframe for emotion of files\n","emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n","\n","# dataframe for path of files.\n","path_df = pd.DataFrame(file_path, columns=['Path'])\n","\n","# dataframe of the emotions and path combined.\n","Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n","\n","# changing integers to actual emotions.\n","Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n","\n","# shuffling the data\n","Ravdess_df = Ravdess_df.sample(frac=1).reset_index(drop=True)\n","Ravdess_df.head(10)"]},{"cell_type":"markdown","metadata":{"id":"xAAWUJD5JDiv"},"source":["# Crema"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":461,"status":"ok","timestamp":1728576987254,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"a1l95clhJFr7","outputId":"83dc1bc3-aebf-44ab-ef8e-4ea4f4d654a4"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotions</th>\n","      <th>Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>angry</td>\n","      <td>../dataset/Crema/1067_IEO_ANG_LO.wav</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>fear</td>\n","      <td>../dataset/Crema/1054_IEO_FEA_MD.wav</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>fear</td>\n","      <td>../dataset/Crema/1075_TIE_FEA_XX.wav</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>disgust</td>\n","      <td>../dataset/Crema/1041_IEO_DIS_MD.wav</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>happy</td>\n","      <td>../dataset/Crema/1086_IWW_HAP_XX.wav</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7437</th>\n","      <td>fear</td>\n","      <td>../dataset/Crema/1076_WSI_FEA_XX.wav</td>\n","    </tr>\n","    <tr>\n","      <th>7438</th>\n","      <td>happy</td>\n","      <td>../dataset/Crema/1028_IEO_HAP_HI.wav</td>\n","    </tr>\n","    <tr>\n","      <th>7439</th>\n","      <td>happy</td>\n","      <td>../dataset/Crema/1041_TIE_HAP_XX.wav</td>\n","    </tr>\n","    <tr>\n","      <th>7440</th>\n","      <td>angry</td>\n","      <td>../dataset/Crema/1031_DFA_ANG_XX.wav</td>\n","    </tr>\n","    <tr>\n","      <th>7441</th>\n","      <td>happy</td>\n","      <td>../dataset/Crema/1007_IEO_HAP_MD.wav</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7442 rows × 2 columns</p>\n","</div>"],"text/plain":["     Emotions                                  Path\n","0       angry  ../dataset/Crema/1067_IEO_ANG_LO.wav\n","1        fear  ../dataset/Crema/1054_IEO_FEA_MD.wav\n","2        fear  ../dataset/Crema/1075_TIE_FEA_XX.wav\n","3     disgust  ../dataset/Crema/1041_IEO_DIS_MD.wav\n","4       happy  ../dataset/Crema/1086_IWW_HAP_XX.wav\n","...       ...                                   ...\n","7437     fear  ../dataset/Crema/1076_WSI_FEA_XX.wav\n","7438    happy  ../dataset/Crema/1028_IEO_HAP_HI.wav\n","7439    happy  ../dataset/Crema/1041_TIE_HAP_XX.wav\n","7440    angry  ../dataset/Crema/1031_DFA_ANG_XX.wav\n","7441    happy  ../dataset/Crema/1007_IEO_HAP_MD.wav\n","\n","[7442 rows x 2 columns]"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["crema_directory_list = os.listdir(Crema)\n","\n","file_emotion = []\n","file_path = []\n","\n","for file in crema_directory_list:\n","    # storing file paths\n","    file_path.append(Crema + file)\n","    # storing file emotions\n","    part=file.split('_')\n","    if part[2] == 'SAD':\n","        file_emotion.append('sad')\n","    elif part[2] == 'ANG':\n","        file_emotion.append('angry')\n","    elif part[2] == 'DIS':\n","        file_emotion.append('disgust')\n","    elif part[2] == 'FEA':\n","        file_emotion.append('fear')\n","    elif part[2] == 'HAP':\n","        file_emotion.append('happy')\n","    elif part[2] == 'NEU':\n","        file_emotion.append('neutral')\n","    else:\n","        file_emotion.append('Unknown')\n","\n","# dataframe for emotion of files\n","emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n","\n","# dataframe for path of files.\n","path_df = pd.DataFrame(file_path, columns=['Path'])\n","Crema_df = pd.concat([emotion_df, path_df], axis=1)\n","Crema_df = Crema_df.sample(frac=1).reset_index(drop=True)\n","Crema_df"]},{"cell_type":"markdown","metadata":{"id":"YMnkIqVEJHTk"},"source":["# TESS"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":433,"status":"ok","timestamp":1728576990564,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"DM9lGkksJJtj","outputId":"2fd33126-3feb-4548-c487-d38772f69f28"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotions</th>\n","      <th>Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>disgust</td>\n","      <td>../dataset/Tess/OAF_disgust/OAF_bath_disgust.wav</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sad</td>\n","      <td>../dataset/Tess/YAF_sad/YAF_soup_sad.wav</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>happy</td>\n","      <td>../dataset/Tess/OAF_happy/OAF_mess_happy.wav</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>angry</td>\n","      <td>../dataset/Tess/OAF_angry/OAF_whip_angry.wav</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>neutral</td>\n","      <td>../dataset/Tess/OAF_neutral/OAF_chalk_neutral.wav</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Emotions                                               Path\n","0  disgust   ../dataset/Tess/OAF_disgust/OAF_bath_disgust.wav\n","1      sad           ../dataset/Tess/YAF_sad/YAF_soup_sad.wav\n","2    happy       ../dataset/Tess/OAF_happy/OAF_mess_happy.wav\n","3    angry       ../dataset/Tess/OAF_angry/OAF_whip_angry.wav\n","4  neutral  ../dataset/Tess/OAF_neutral/OAF_chalk_neutral.wav"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["tess_directory_list = os.listdir(Tess)\n","\n","file_emotion = []\n","file_path = []\n","\n","for dir in tess_directory_list:\n","    directories = os.listdir(Tess + dir)\n","    for file in directories:\n","        part = file.split('.')[0]\n","        part = part.split('_')[2]\n","        if part=='ps':\n","            file_emotion.append('surprise')\n","        else:\n","            file_emotion.append(part)\n","        file_path.append(Tess + dir + '/' + file)\n","\n","# dataframe for emotion of files\n","emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n","\n","# dataframe for path of files.\n","path_df = pd.DataFrame(file_path, columns=['Path'])\n","Tess_df = pd.concat([emotion_df, path_df], axis=1)\n","Tess_df = Tess_df.sample(frac=1).reset_index(drop=True)\n","\n","Tess_df.head()"]},{"cell_type":"markdown","metadata":{"id":"5r3C2PqvJLxR"},"source":["# Savee"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":512,"status":"ok","timestamp":1728576994787,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"rm5pPwpfJ29Z","outputId":"be190e65-2abf-4f68-efb3-571483d4e36c"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotions</th>\n","      <th>Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sad</td>\n","      <td>../dataset/Savee/JK_sa04.wav</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>angry</td>\n","      <td>../dataset/Savee/JE_a10.wav</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sad</td>\n","      <td>../dataset/Savee/JK_sa14.wav</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>sad</td>\n","      <td>../dataset/Savee/DC_sa12.wav</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fear</td>\n","      <td>../dataset/Savee/JE_f10.wav</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Emotions                          Path\n","0      sad  ../dataset/Savee/JK_sa04.wav\n","1    angry   ../dataset/Savee/JE_a10.wav\n","2      sad  ../dataset/Savee/JK_sa14.wav\n","3      sad  ../dataset/Savee/DC_sa12.wav\n","4     fear   ../dataset/Savee/JE_f10.wav"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["savee_directory_list = os.listdir(Savee)\n","\n","file_emotion = []\n","file_path = []\n","\n","for file in savee_directory_list:\n","    file_path.append(Savee + file)\n","    part = file.split('_')[1]\n","    ele = part[:-6]\n","    if ele=='a':\n","        file_emotion.append('angry')\n","    elif ele=='d':\n","        file_emotion.append('disgust')\n","    elif ele=='f':\n","        file_emotion.append('fear')\n","    elif ele=='h':\n","        file_emotion.append('happy')\n","    elif ele=='n':\n","        file_emotion.append('neutral')\n","    elif ele=='sa':\n","        file_emotion.append('sad')\n","    else:\n","        file_emotion.append('surprise')\n","\n","# dataframe for emotion of files\n","emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n","\n","# dataframe for path of files.\n","path_df = pd.DataFrame(file_path, columns=['Path'])\n","Savee_df = pd.concat([emotion_df, path_df], axis=1)\n","Savee_df = Savee_df.sample(frac=1).reset_index(drop=True)\n","\n","Savee_df.head()"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1728588978689,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"PMwJ79bdKPb_","outputId":"0afa8900-a5a7-48d9-a27c-2f9e809de352"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Emotions</th>\n","      <th>Path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>happy</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>happy</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>neutral</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>disgust</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>fear</td>\n","      <td>../dataset/Ravdess/audio_speech_actors_01-24/A...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Emotions                                               Path\n","0    happy  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","1    happy  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","2  neutral  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","3  disgust  ../dataset/Ravdess/audio_speech_actors_01-24/A...\n","4     fear  ../dataset/Ravdess/audio_speech_actors_01-24/A..."]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# creating Dataframe using all the 4 dataframes we created so far.\n","data_path = pd.concat([Ravdess_df, Crema_df, Tess_df, Savee_df], axis = 0)\n","data_path.to_csv(\"../utils/data_path.csv\",index=False)\n","data_path.head()"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":454,"status":"ok","timestamp":1728589027846,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"9tRBGcUY7qHO"},"outputs":[],"source":["# To make our model to learn and adapt to real-life situations, as noise stimulates the real-life situations\n","def noise(data):\n","    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n","    data = data + noise_amp*np.random.normal(size=data.shape[0])\n","    return data\n","\n","# Stretching the audio file will include making it fast and slow, allowing our model to detect emotions in both slow and fast speech.\n","def stretch(data, rate=0.8):\n","    return librosa.effects.time_stretch(data, rate=rate)\n","\n","# Time shifting stimulates the start of the audio, allowing our model to learn when the audio starts in an audio file.\n","def shift(data):\n","    shift_range = int(np.random.uniform(low=-5, high = 5)*1000)\n","    return np.roll(data, shift_range)\n","\n","# To help model with high and low pitches\n","def pitch(data, sampling_rate, pitch_factor=0.7):\n","    return librosa.effects.pitch_shift(data,sr=sampling_rate, n_steps=pitch_factor)\n","\n","# Taking any example and checking for techniques.\n","path = np.array(data_path.Path)[1]\n","data, sample_rate = librosa.load(path)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":451,"status":"ok","timestamp":1728589032293,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"N4VjdU6I7wGU"},"outputs":[],"source":["def extract_features(data):\n","    # ZCR\n","    # The zero-crossing rate is the rate at which the audio signal changes from positive to negative or vice versa. It gives an idea of how noisy or percussive the signal is.\n","    # This feature is useful when playing with audios having high disturbance or unvoiced sounds.\n","    result = np.array([])\n","    zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n","    result=np.hstack((result, zcr)) # stacking horizontally\n","\n","    # Chroma_stft\n","    # This feature is useful for identifying harmonic and pitch-related information, which can help distinguish different emotions in speech (e.g., sadness may have a different harmonic pattern than excitement).\n","    stft = np.abs(librosa.stft(data))\n","    chroma_stft = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T, axis=0)\n","    result = np.hstack((result, chroma_stft)) # stacking horizontally\n","\n","    # MFCC\n","    # MFCCs are highly effective in speech and emotion recognition because they model how humans perceive sound, focusing on the most important features of speech.\n","    mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate).T, axis=0)\n","    result = np.hstack((result, mfcc)) # stacking horizontally\n","\n","    # Root Mean Square Value\n","    # RMS is useful for distinguishing between different speech emotions. For example, speech with higher energy may indicate excitement or anger, while lower energy may indicate calmness or sadness.\n","    rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n","    result = np.hstack((result, rms)) # stacking horizontally\n","\n","    # MelSpectogram\n","    # The Mel spectrogram captures the timbre and texture of the audio, which can be crucial for recognizing the emotional content of speech. For instance, anger or excitement might have more energy in higher-frequency bands, while sadness might be more present in lower frequencies.\n","    mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sample_rate).T, axis=0)\n","    result = np.hstack((result, mel)) # stacking horizontally\n","\n","    return result\n","\n","def get_features(path):\n","    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n","    data, sample_rate = librosa.load(path, duration=2.5, offset=0.6)\n","\n","    # without augmentation\n","    res1 = extract_features(data)\n","    result = np.array(res1)\n","\n","    # data with noise\n","    noise_data = noise(data)\n","    res2 = extract_features(noise_data)\n","    result = np.vstack((result, res2)) # stacking vertically\n","\n","    # data with stretching and pitching\n","    new_data = stretch(data)\n","    data_stretch_pitch = pitch(new_data, sample_rate)\n","    res3 = extract_features(data_stretch_pitch)\n","    result = np.vstack((result, res3)) # stacking vertically\n","\n","    return result"]},{"cell_type":"markdown","metadata":{},"source":["# Splitting Data\n","We are augmenting our dataset with 3 different techniques \n","* Without Augmentation \n","* Data with noise\n","* Data with stretching and pitching"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3019369,"status":"ok","timestamp":1728592055601,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"6tPnQgy07y-Z","outputId":"14ea6d68-0167-4e4f-d125-b9cb37f3adc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["CPU times: total: 9min 17s\n","Wall time: 30min 53s\n"]}],"source":["%%time\n","X, Y = [], []\n","for path, emotion in zip(data_path.Path, data_path.Emotions):\n","    feature = get_features(path)\n","    for ele in feature:\n","        X.append(ele)\n","        # appending emotion 3 times as we have made 3 augmentation techniques on each audio file.\n","        Y.append(emotion)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":511,"status":"ok","timestamp":1728592133919,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"oUWOudWkHrEW","outputId":"6e7f9653-819c-4b18-a634-8c5565bdf428"},"outputs":[{"data":{"text/plain":["(36486, 36486, (12162,))"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["len(X), len(Y), data_path.Path.shape"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"elapsed":21203,"status":"ok","timestamp":1728592163522,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"AmfcxAD1HsYU","outputId":"e860ad01-f97d-4cb5-cb0d-1b064aec4490"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>16</th>\n","      <th>17</th>\n","      <th>18</th>\n","      <th>19</th>\n","      <th>20</th>\n","      <th>21</th>\n","      <th>22</th>\n","      <th>23</th>\n","      <th>24</th>\n","      <th>25</th>\n","      <th>26</th>\n","      <th>27</th>\n","      <th>28</th>\n","      <th>29</th>\n","      <th>30</th>\n","      <th>31</th>\n","      <th>32</th>\n","      <th>33</th>\n","      <th>34</th>\n","      <th>35</th>\n","      <th>36</th>\n","      <th>37</th>\n","      <th>38</th>\n","      <th>39</th>\n","      <th>...</th>\n","      <th>123</th>\n","      <th>124</th>\n","      <th>125</th>\n","      <th>126</th>\n","      <th>127</th>\n","      <th>128</th>\n","      <th>129</th>\n","      <th>130</th>\n","      <th>131</th>\n","      <th>132</th>\n","      <th>133</th>\n","      <th>134</th>\n","      <th>135</th>\n","      <th>136</th>\n","      <th>137</th>\n","      <th>138</th>\n","      <th>139</th>\n","      <th>140</th>\n","      <th>141</th>\n","      <th>142</th>\n","      <th>143</th>\n","      <th>144</th>\n","      <th>145</th>\n","      <th>146</th>\n","      <th>147</th>\n","      <th>148</th>\n","      <th>149</th>\n","      <th>150</th>\n","      <th>151</th>\n","      <th>152</th>\n","      <th>153</th>\n","      <th>154</th>\n","      <th>155</th>\n","      <th>156</th>\n","      <th>157</th>\n","      <th>158</th>\n","      <th>159</th>\n","      <th>160</th>\n","      <th>161</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.219157</td>\n","      <td>0.691433</td>\n","      <td>0.667136</td>\n","      <td>0.615862</td>\n","      <td>0.636741</td>\n","      <td>0.612271</td>\n","      <td>0.563172</td>\n","      <td>0.589636</td>\n","      <td>0.577268</td>\n","      <td>0.538605</td>\n","      <td>0.573550</td>\n","      <td>0.620119</td>\n","      <td>0.679081</td>\n","      <td>-389.310089</td>\n","      <td>44.604862</td>\n","      <td>-22.185759</td>\n","      <td>8.823205</td>\n","      <td>-6.492015</td>\n","      <td>-17.190641</td>\n","      <td>-12.072454</td>\n","      <td>-10.507295</td>\n","      <td>-9.845922</td>\n","      <td>1.190978</td>\n","      <td>-13.185540</td>\n","      <td>-5.775838</td>\n","      <td>-0.716264</td>\n","      <td>-6.928237</td>\n","      <td>-5.893147</td>\n","      <td>-8.138218</td>\n","      <td>-1.948143</td>\n","      <td>-0.507945</td>\n","      <td>1.597394</td>\n","      <td>4.096745</td>\n","      <td>0.028427</td>\n","      <td>0.010388</td>\n","      <td>0.002234</td>\n","      <td>0.000901</td>\n","      <td>0.000676</td>\n","      <td>0.001357</td>\n","      <td>0.024204</td>\n","      <td>...</td>\n","      <td>0.033903</td>\n","      <td>0.024785</td>\n","      <td>0.025461</td>\n","      <td>0.007359</td>\n","      <td>0.003066</td>\n","      <td>0.005026</td>\n","      <td>0.002904</td>\n","      <td>0.002267</td>\n","      <td>0.003510</td>\n","      <td>0.008899</td>\n","      <td>0.010553</td>\n","      <td>0.015689</td>\n","      <td>0.009416</td>\n","      <td>0.011137</td>\n","      <td>0.004788</td>\n","      <td>0.004688</td>\n","      <td>0.003358</td>\n","      <td>0.003425</td>\n","      <td>0.003716</td>\n","      <td>0.003637</td>\n","      <td>0.002551</td>\n","      <td>0.003321</td>\n","      <td>0.004074</td>\n","      <td>0.003392</td>\n","      <td>0.002228</td>\n","      <td>0.001928</td>\n","      <td>0.002257</td>\n","      <td>0.003255</td>\n","      <td>0.001603</td>\n","      <td>0.001273</td>\n","      <td>0.001556</td>\n","      <td>0.003427</td>\n","      <td>0.005109</td>\n","      <td>0.006119</td>\n","      <td>0.007552</td>\n","      <td>0.005767</td>\n","      <td>0.003263</td>\n","      <td>0.001742</td>\n","      <td>0.000233</td>\n","      <td>happy</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.329454</td>\n","      <td>0.745107</td>\n","      <td>0.776924</td>\n","      <td>0.755002</td>\n","      <td>0.763561</td>\n","      <td>0.764032</td>\n","      <td>0.670636</td>\n","      <td>0.659072</td>\n","      <td>0.648103</td>\n","      <td>0.624234</td>\n","      <td>0.634966</td>\n","      <td>0.659839</td>\n","      <td>0.711413</td>\n","      <td>-214.096323</td>\n","      <td>14.352454</td>\n","      <td>-2.522039</td>\n","      <td>0.929195</td>\n","      <td>-3.139962</td>\n","      <td>-7.037210</td>\n","      <td>-5.042682</td>\n","      <td>-5.556265</td>\n","      <td>-4.761097</td>\n","      <td>-2.794272</td>\n","      <td>-4.224562</td>\n","      <td>-3.806318</td>\n","      <td>-1.707880</td>\n","      <td>-3.459285</td>\n","      <td>-4.111840</td>\n","      <td>-3.746040</td>\n","      <td>-2.256215</td>\n","      <td>-0.051007</td>\n","      <td>0.845458</td>\n","      <td>2.895086</td>\n","      <td>0.032850</td>\n","      <td>0.016199</td>\n","      <td>0.008063</td>\n","      <td>0.008627</td>\n","      <td>0.009107</td>\n","      <td>0.010071</td>\n","      <td>0.028292</td>\n","      <td>...</td>\n","      <td>0.042021</td>\n","      <td>0.033360</td>\n","      <td>0.033674</td>\n","      <td>0.013887</td>\n","      <td>0.010415</td>\n","      <td>0.011627</td>\n","      <td>0.009836</td>\n","      <td>0.009249</td>\n","      <td>0.010294</td>\n","      <td>0.016287</td>\n","      <td>0.017275</td>\n","      <td>0.023458</td>\n","      <td>0.016971</td>\n","      <td>0.018805</td>\n","      <td>0.012488</td>\n","      <td>0.011836</td>\n","      <td>0.009995</td>\n","      <td>0.010639</td>\n","      <td>0.010178</td>\n","      <td>0.010675</td>\n","      <td>0.009386</td>\n","      <td>0.010632</td>\n","      <td>0.011498</td>\n","      <td>0.009794</td>\n","      <td>0.009208</td>\n","      <td>0.009298</td>\n","      <td>0.009217</td>\n","      <td>0.010439</td>\n","      <td>0.008639</td>\n","      <td>0.008308</td>\n","      <td>0.008255</td>\n","      <td>0.010496</td>\n","      <td>0.012512</td>\n","      <td>0.014699</td>\n","      <td>0.015044</td>\n","      <td>0.012488</td>\n","      <td>0.010466</td>\n","      <td>0.008846</td>\n","      <td>0.007468</td>\n","      <td>happy</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.180624</td>\n","      <td>0.690494</td>\n","      <td>0.630426</td>\n","      <td>0.612377</td>\n","      <td>0.548845</td>\n","      <td>0.602829</td>\n","      <td>0.568806</td>\n","      <td>0.583996</td>\n","      <td>0.586410</td>\n","      <td>0.561694</td>\n","      <td>0.527813</td>\n","      <td>0.561941</td>\n","      <td>0.615647</td>\n","      <td>-446.122284</td>\n","      <td>41.606640</td>\n","      <td>-25.104706</td>\n","      <td>9.550559</td>\n","      <td>-8.946218</td>\n","      <td>-17.385601</td>\n","      <td>-14.084661</td>\n","      <td>-11.910576</td>\n","      <td>-8.615192</td>\n","      <td>1.579874</td>\n","      <td>-13.617373</td>\n","      <td>-1.983365</td>\n","      <td>-2.542864</td>\n","      <td>-7.308558</td>\n","      <td>-6.744491</td>\n","      <td>-5.923739</td>\n","      <td>0.574276</td>\n","      <td>1.544911</td>\n","      <td>3.857584</td>\n","      <td>5.224770</td>\n","      <td>0.012973</td>\n","      <td>0.002613</td>\n","      <td>0.000618</td>\n","      <td>0.000283</td>\n","      <td>0.000284</td>\n","      <td>0.000142</td>\n","      <td>0.005552</td>\n","      <td>...</td>\n","      <td>0.004571</td>\n","      <td>0.007452</td>\n","      <td>0.007168</td>\n","      <td>0.006677</td>\n","      <td>0.003708</td>\n","      <td>0.001116</td>\n","      <td>0.000891</td>\n","      <td>0.001125</td>\n","      <td>0.000409</td>\n","      <td>0.000523</td>\n","      <td>0.001202</td>\n","      <td>0.002730</td>\n","      <td>0.002100</td>\n","      <td>0.002061</td>\n","      <td>0.002036</td>\n","      <td>0.001869</td>\n","      <td>0.001370</td>\n","      <td>0.001009</td>\n","      <td>0.000703</td>\n","      <td>0.000822</td>\n","      <td>0.000992</td>\n","      <td>0.000917</td>\n","      <td>0.000643</td>\n","      <td>0.001072</td>\n","      <td>0.000881</td>\n","      <td>0.000537</td>\n","      <td>0.000461</td>\n","      <td>0.000383</td>\n","      <td>0.000578</td>\n","      <td>0.000453</td>\n","      <td>0.000333</td>\n","      <td>0.000258</td>\n","      <td>0.000428</td>\n","      <td>0.001138</td>\n","      <td>0.001421</td>\n","      <td>0.001315</td>\n","      <td>0.001306</td>\n","      <td>0.000455</td>\n","      <td>0.000043</td>\n","      <td>happy</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.155834</td>\n","      <td>0.617245</td>\n","      <td>0.597271</td>\n","      <td>0.566049</td>\n","      <td>0.538231</td>\n","      <td>0.530569</td>\n","      <td>0.443821</td>\n","      <td>0.479569</td>\n","      <td>0.547259</td>\n","      <td>0.514224</td>\n","      <td>0.483463</td>\n","      <td>0.486443</td>\n","      <td>0.576259</td>\n","      <td>-327.932617</td>\n","      <td>35.423176</td>\n","      <td>-20.308094</td>\n","      <td>4.352321</td>\n","      <td>-11.217619</td>\n","      <td>-3.791472</td>\n","      <td>-22.043650</td>\n","      <td>-15.588261</td>\n","      <td>-11.681346</td>\n","      <td>-19.524824</td>\n","      <td>1.544646</td>\n","      <td>-12.672573</td>\n","      <td>-11.721163</td>\n","      <td>-2.973376</td>\n","      <td>-12.307690</td>\n","      <td>-3.504480</td>\n","      <td>-11.080645</td>\n","      <td>-2.704814</td>\n","      <td>-1.517587</td>\n","      <td>-7.291881</td>\n","      <td>0.051731</td>\n","      <td>0.017751</td>\n","      <td>0.001004</td>\n","      <td>0.000718</td>\n","      <td>0.000682</td>\n","      <td>0.000677</td>\n","      <td>0.004671</td>\n","      <td>...</td>\n","      <td>0.042382</td>\n","      <td>0.007467</td>\n","      <td>0.009406</td>\n","      <td>0.004731</td>\n","      <td>0.004817</td>\n","      <td>0.008351</td>\n","      <td>0.014432</td>\n","      <td>0.026922</td>\n","      <td>0.043614</td>\n","      <td>0.063168</td>\n","      <td>0.056716</td>\n","      <td>0.070787</td>\n","      <td>0.056882</td>\n","      <td>0.041463</td>\n","      <td>0.014382</td>\n","      <td>0.010063</td>\n","      <td>0.010356</td>\n","      <td>0.007357</td>\n","      <td>0.006951</td>\n","      <td>0.004216</td>\n","      <td>0.005800</td>\n","      <td>0.005278</td>\n","      <td>0.004526</td>\n","      <td>0.004202</td>\n","      <td>0.005765</td>\n","      <td>0.005739</td>\n","      <td>0.004184</td>\n","      <td>0.003794</td>\n","      <td>0.004106</td>\n","      <td>0.004206</td>\n","      <td>0.004710</td>\n","      <td>0.004816</td>\n","      <td>0.005614</td>\n","      <td>0.006275</td>\n","      <td>0.007023</td>\n","      <td>0.006955</td>\n","      <td>0.005516</td>\n","      <td>0.002728</td>\n","      <td>0.000197</td>\n","      <td>happy</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.251135</td>\n","      <td>0.719829</td>\n","      <td>0.702356</td>\n","      <td>0.649794</td>\n","      <td>0.644915</td>\n","      <td>0.627301</td>\n","      <td>0.527844</td>\n","      <td>0.532246</td>\n","      <td>0.599953</td>\n","      <td>0.570876</td>\n","      <td>0.549004</td>\n","      <td>0.576111</td>\n","      <td>0.687266</td>\n","      <td>-195.275082</td>\n","      <td>19.604292</td>\n","      <td>-3.163328</td>\n","      <td>-0.127980</td>\n","      <td>-4.280029</td>\n","      <td>-2.259832</td>\n","      <td>-9.010055</td>\n","      <td>-7.465660</td>\n","      <td>-4.562930</td>\n","      <td>-7.164631</td>\n","      <td>0.478484</td>\n","      <td>-3.603180</td>\n","      <td>-4.710583</td>\n","      <td>-2.745778</td>\n","      <td>-6.293137</td>\n","      <td>-2.911897</td>\n","      <td>-5.670152</td>\n","      <td>-2.328435</td>\n","      <td>-1.085830</td>\n","      <td>-6.819318</td>\n","      <td>0.054536</td>\n","      <td>0.025172</td>\n","      <td>0.008426</td>\n","      <td>0.008803</td>\n","      <td>0.007774</td>\n","      <td>0.007983</td>\n","      <td>0.012188</td>\n","      <td>...</td>\n","      <td>0.049392</td>\n","      <td>0.015066</td>\n","      <td>0.017050</td>\n","      <td>0.012675</td>\n","      <td>0.012021</td>\n","      <td>0.015368</td>\n","      <td>0.022189</td>\n","      <td>0.035432</td>\n","      <td>0.049493</td>\n","      <td>0.068756</td>\n","      <td>0.064688</td>\n","      <td>0.079747</td>\n","      <td>0.068307</td>\n","      <td>0.049623</td>\n","      <td>0.021270</td>\n","      <td>0.017627</td>\n","      <td>0.017413</td>\n","      <td>0.014199</td>\n","      <td>0.014324</td>\n","      <td>0.011496</td>\n","      <td>0.013734</td>\n","      <td>0.012734</td>\n","      <td>0.011704</td>\n","      <td>0.011770</td>\n","      <td>0.013020</td>\n","      <td>0.013213</td>\n","      <td>0.011557</td>\n","      <td>0.011967</td>\n","      <td>0.011737</td>\n","      <td>0.011617</td>\n","      <td>0.011539</td>\n","      <td>0.012486</td>\n","      <td>0.013517</td>\n","      <td>0.013621</td>\n","      <td>0.014454</td>\n","      <td>0.014626</td>\n","      <td>0.012705</td>\n","      <td>0.010159</td>\n","      <td>0.007395</td>\n","      <td>happy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 163 columns</p>\n","</div>"],"text/plain":["          0         1         2         3  ...       159       160       161  labels\n","0  0.219157  0.691433  0.667136  0.615862  ...  0.003263  0.001742  0.000233   happy\n","1  0.329454  0.745107  0.776924  0.755002  ...  0.010466  0.008846  0.007468   happy\n","2  0.180624  0.690494  0.630426  0.612377  ...  0.001306  0.000455  0.000043   happy\n","3  0.155834  0.617245  0.597271  0.566049  ...  0.005516  0.002728  0.000197   happy\n","4  0.251135  0.719829  0.702356  0.649794  ...  0.012705  0.010159  0.007395   happy\n","\n","[5 rows x 163 columns]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["Features = pd.DataFrame(X)\n","Features['labels'] = Y\n","Features.to_csv('../utils/features.csv', index=False)\n","Features.head()"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":495,"status":"ok","timestamp":1728592199045,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"6XDAXAFJHua8"},"outputs":[],"source":["# Features = pd.read_csv(\"../utils/features.csv\")\n","X = Features.iloc[: ,:-1].values\n","Y = Features['labels'].values"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":440,"status":"ok","timestamp":1728592200809,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"RiVBuKViHwPH"},"outputs":[],"source":["# As this is a multiclass classification problem onehotencoding our Y.\n","encoder = OneHotEncoder()\n","Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"]},{"cell_type":"code","execution_count":28,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1151,"status":"ok","timestamp":1728592285465,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"UiIfuxEcHx2L","outputId":"cb39593f-29a2-482c-f7f9-34bc3e436293"},"outputs":[{"data":{"text/plain":["((23350, 162), (23350, 8), (5838, 162), (5838, 8), (7298, 162), (7298, 8))"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["\n","# First split into train and test\n","x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0, shuffle=True)\n","\n","# Further split train into train and validation sets\n","x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=0, shuffle=True)\n","\n","# Check the shapes of the resulting splits\n","x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape\n"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":436,"status":"ok","timestamp":1728592288983,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"tJS-aqvCHz4V","outputId":"226d6d2b-efb4-4649-e61d-101959179d2d"},"outputs":[{"data":{"text/plain":["((23350, 162), (23350, 8), (7298, 162), (7298, 8))"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["# scaling our data with sklearn's Standard scaler\n","scaler = StandardScaler()\n","x_train = scaler.fit_transform(x_train)\n","x_test = scaler.transform(x_test)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"]},{"cell_type":"code","execution_count":30,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":419,"status":"ok","timestamp":1728592292233,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"0Q1uWgFxH1QA","outputId":"cd0765de-44fd-48c5-c824-5f5020189fe5"},"outputs":[{"data":{"text/plain":["((23350, 162, 1), (23350, 8), (7298, 162), (7298, 8))"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["# making our data compatible to model.\n","x_train = np.expand_dims(x_train, axis=2)\n","# x_test = np.expand_dims(x_test, axis=2)\n","x_train.shape, y_train.shape, x_test.shape, y_test.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Outlining our model\n","we will use 1D convolutional neural networks which are great for the data related to time-series data like audios, videos. In our case we are dealing with audio files, which can be treated as time-series data where features like MFCC, chroma etc. are extracted over different time windows. 1 CNN work particularly well for such data because they can effectively capture pattern and features along the time-axis, identifying important temporal features like pitch, tone, and rhythm that help differentiate emotions"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":600},"executionInfo":{"elapsed":827,"status":"ok","timestamp":1728592295102,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"fQzmkxSpH25v","outputId":"c501fe54-63a9-41b1-d3d0-cadb91e7186b"},"outputs":[{"ename":"ValueError","evalue":"Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow.python.keras.layers.recurrent.LSTM object at 0x00000299263109B0> (of type <class 'tensorflow.python.keras.layers.recurrent.LSTM'>)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[35], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m KERNEL_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m      8\u001b[0m POOL_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# Applying a convolutional layer with 256 filters, with kernel size of 5 and activation function \"relu\" which is used to induce non-linearity to make it non-linear which is essential to deal with real-life situations\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFIRST_LAYER_FILTER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKERNEL_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# Pooling is used to downsampling the feature maps, summarizing importand information by taking the maximum value in each window of KERNEL_SIZE, which helps to reduce to computational complexity prevents overffitting, while preserving important patterns.\u001b[39;49;00m\n\u001b[0;32m     14\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mMaxPooling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPOOL_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# Stacking Convolutional layers allows the model to learn hierarchical features. The inital layer capture low-level features while deeper layers capture more abstract features.\u001b[39;49;00m\n\u001b[0;32m     16\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# You progressively reduce the number of filters (256 → 128 → 64), making the model lighter as the features become more abstract.\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mBatchNormalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSECOND_LAYER_FILTER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKERNEL_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mMaxPooling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPOOL_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mBatchNormalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mConv1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTHIRD_LAYER_FILTER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mKERNEL_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mMaxPooling1D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPOOL_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msame\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# The regularization technique randomly turns off 20% of neurons during training, helping to prevent overfitting by encouriging the network to be more robust and not rely on specific neurons.\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mBatchNormalization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# Flattening converts the 3D output from the Conv1D and MaxPooling layers into a 1D vector, which can be passed to fully connected (Dense) layers. This transformation is necessary for classification\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# Here starts our hidden-layers\u001b[39;49;00m\n\u001b[0;32m     32\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFIRST_HIDDEN_LAYER_INPUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# Turning off 30% neurons\u001b[39;49;00m\n\u001b[0;32m     34\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m\t\t\u001b[49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSECOND_HIDDEN_LAYER_INPUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m\t\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m\t\t\t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m , loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m , metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     39\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n","File \u001b[1;32mc:\\Users\\saadq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py:75\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[1;34m(self, layers, trainable, name)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layers:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[1;32m---> 75\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrebuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_rebuild()\n","File \u001b[1;32mc:\\Users\\saadq\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\models\\sequential.py:97\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer, rebuild)\u001b[0m\n\u001b[0;32m     95\u001b[0m         layer \u001b[38;5;241m=\u001b[39m origin_layer\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Layer):\n\u001b[1;32m---> 97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly instances of `keras.Layer` can be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madded to a Sequential model. Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(layer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_layer_name_unique(layer):\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll layers added to a Sequential model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have unique names. Name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe name of a layer in this model. Update the `name` argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto pass a unique name.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow.python.keras.layers.recurrent.LSTM object at 0x00000299263109B0> (of type <class 'tensorflow.python.keras.layers.recurrent.LSTM'>)"]}],"source":["FIRST_LAYER_FILTER = 256\n","SECOND_LAYER_FILTER = 256\n","THIRD_LAYER_FILTER = 128\n","FOURTH_LAYER_FILTER = 64\n","FIRST_HIDDEN_LAYER_INPUT = 32\n","SECOND_HIDDEN_LAYER_INPUT = 8\n","KERNEL_SIZE = 5\n","POOL_SIZE = 5\n","model = Sequential(\n","\t[\n","\t\t# Applying a convolutional layer with 256 filters, with kernel size of 5 and activation function \"relu\" which is used to induce non-linearity to make it non-linear which is essential to deal with real-life situations\n","\t\tConv1D(FIRST_LAYER_FILTER, kernel_size=KERNEL_SIZE, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)),\n","\t\t# Pooling is used to downsampling the feature maps, summarizing importand information by taking the maximum value in each window of KERNEL_SIZE, which helps to reduce to computational complexity prevents overffitting, while preserving important patterns.\n","\t\tMaxPooling1D(pool_size=POOL_SIZE, strides=2, padding='same'),\n","\t\t# Stacking Convolutional layers allows the model to learn hierarchical features. The inital layer capture low-level features while deeper layers capture more abstract features.\n","\t\t# You progressively reduce the number of filters (256 → 128 → 64), making the model lighter as the features become more abstract.\n","\t\tBatchNormalization(),\n","\t\tConv1D(SECOND_LAYER_FILTER, kernel_size=KERNEL_SIZE, strides=1, padding='same', activation='relu'),\n","\t\tMaxPooling1D(pool_size=POOL_SIZE, strides=2, padding='same'),\n","\t\tBatchNormalization(),\n","\t\tConv1D(THIRD_LAYER_FILTER, kernel_size=KERNEL_SIZE, strides=1, padding='same', activation='relu'),\n","\t\tMaxPooling1D(pool_size=POOL_SIZE, strides=2, padding='same'),\n","\t\t# The regularization technique randomly turns off 20% of neurons during training, helping to prevent overfitting by encouriging the network to be more robust and not rely on specific neurons.\n","\t\tDropout(0.3),\n","\t\tBatchNormalization(),\n","\t\tLSTM(64, return_sequences=True),\n","\t\tLSTM(64, return_sequences=False),\n","\t\tDropout(0.4),\n","\t\t# Flattening converts the 3D output from the Conv1D and MaxPooling layers into a 1D vector, which can be passed to fully connected (Dense) layers. This transformation is necessary for classification\n","\t\tFlatten(),\n","\t\t# Here starts our hidden-layers\n","\t\tDense(units=FIRST_HIDDEN_LAYER_INPUT, activation='relu'),\n","\t\t# Turning off 30% neurons\n","\t\tDropout(0.5),\n","\t\tDense(units=SECOND_HIDDEN_LAYER_INPUT, activation='softmax'),\n","\t]\n","\t\t\t)\n","model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n","model.summary()\n"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_1\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">162</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">81</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_11          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ conv1d_9 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m162\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │         \u001b[38;5;34m1,536\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_9 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_10 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m81\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m327,936\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_10 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv1d_11 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │       \u001b[38;5;34m163,968\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ max_pooling1d_11 (\u001b[38;5;33mMaxPooling1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ batch_normalization_11          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n","│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m49,408\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m33,024\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">580,776</span> (2.22 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m580,776\u001b[0m (2.22 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">579,496</span> (2.21 MB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m579,496\u001b[0m (2.21 MB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"]},"metadata":{},"output_type":"display_data"}],"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, Flatten, Dense, LSTM, BatchNormalization\n","\n","model = Sequential()\n","\n","# First Convolution Block\n","# Applying a convolutional layer with 256 filters, with kernel size of 5 and activation function \"relu\" which is used to induce non-linearity to make it non-linear which is essential to deal with real-life situations\n","model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu', input_shape=(x_train.shape[1], 1)))\n","# Pooling is used to downsampling the feature maps, summarizing importand information by taking the maximum value in each window of KERNEL_SIZE, which helps to reduce to computational complexity prevents overffitting, while preserving important patterns.\n","model.add(MaxPooling1D(pool_size=5, strides=2, padding='same'))\n","# Stacking Convolutional layers allows the model to learn hierarchical features. The inital layer capture low-level features while deeper layers capture more abstract features.\n","# You progressively reduce the number of filters (256 → 128 → 64), making the model lighter as the features become more abstract.\n","model.add(BatchNormalization())\n","\n","# Second Convolution Block\n","model.add(Conv1D(256, kernel_size=5, strides=1, padding='same', activation='relu'))\n","model.add(MaxPooling1D(pool_size=5, strides=2, padding='same'))\n","model.add(BatchNormalization())\n","\n","# Third Convolution Block\n","model.add(Conv1D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n","model.add(MaxPooling1D(pool_size=5, strides=2, padding='same'))\n","# The regularization technique randomly turns off 20% of neurons during training, helping to prevent overfitting by encouriging the network to be more robust and not rely on specific neurons.\n","model.add(Dropout(0.3))\n","model.add(BatchNormalization())\n","\n","# LSTM Layer for sequential feature extraction\n","model.add(LSTM(64, return_sequences=True))\n","model.add(LSTM(64, return_sequences=False))\n","model.add(Dropout(0.4))\n","\n","# Fully Connected Layers\n","# Flattening converts the 3D output from the Conv1D and MaxPooling layers into a 1D vector, which can be passed to fully connected (Dense) layers. This transformation is necessary for classification\n","\n","model.add(Flatten())\n","model.add(Dense(32, activation='relu'))\n","# Turning off 50% neurons\n","\n","model.add(Dropout(0.5))\n","model.add(Dense(8, activation='softmax'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()\n"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10019894,"status":"ok","timestamp":1728602318160,"user":{"displayName":"ICECUBE SAAD","userId":"09516538256357241813"},"user_tz":-300},"id":"1sHahcFFH5N2","outputId":"05a74471-20b4-4c2e-aaeb-1193aeb65e46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 81ms/step - accuracy: 0.2360 - loss: 1.8808 - val_accuracy: 0.1742 - val_loss: 1.9832 - learning_rate: 0.0010\n","Epoch 2/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 81ms/step - accuracy: 0.3377 - loss: 1.6320 - val_accuracy: 0.1694 - val_loss: 2.2374 - learning_rate: 0.0010\n","Epoch 3/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 82ms/step - accuracy: 0.4012 - loss: 1.5296 - val_accuracy: 0.1889 - val_loss: 2.0431 - learning_rate: 0.0010\n","Epoch 4/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 79ms/step - accuracy: 0.4396 - loss: 1.4386 - val_accuracy: 0.1528 - val_loss: 2.2664 - learning_rate: 0.0010\n","Epoch 5/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 78ms/step - accuracy: 0.4567 - loss: 1.3958 - val_accuracy: 0.2122 - val_loss: 2.1200 - learning_rate: 0.0010\n","Epoch 6/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 83ms/step - accuracy: 0.4701 - loss: 1.3535 - val_accuracy: 0.1845 - val_loss: 2.1774 - learning_rate: 0.0010\n","Epoch 7/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 77ms/step - accuracy: 0.4812 - loss: 1.3273 - val_accuracy: 0.1958 - val_loss: 2.1988 - learning_rate: 0.0010\n","Epoch 8/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 76ms/step - accuracy: 0.4965 - loss: 1.2999 - val_accuracy: 0.2455 - val_loss: 2.1536 - learning_rate: 0.0010\n","Epoch 9/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 77ms/step - accuracy: 0.4899 - loss: 1.2915 - val_accuracy: 0.1547 - val_loss: 2.6822 - learning_rate: 0.0010\n","Epoch 10/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 77ms/step - accuracy: 0.5019 - loss: 1.2740 - val_accuracy: 0.2088 - val_loss: 2.2245 - learning_rate: 0.0010\n","Epoch 11/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 77ms/step - accuracy: 0.5146 - loss: 1.2542 - val_accuracy: 0.1761 - val_loss: 2.5046 - learning_rate: 0.0010\n","Epoch 12/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 77ms/step - accuracy: 0.5247 - loss: 1.2149 - val_accuracy: 0.1939 - val_loss: 2.2291 - learning_rate: 5.0000e-04\n","Epoch 13/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 80ms/step - accuracy: 0.5362 - loss: 1.1925 - val_accuracy: 0.2001 - val_loss: 2.3237 - learning_rate: 2.5000e-04\n","Epoch 14/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 85ms/step - accuracy: 0.5453 - loss: 1.1690 - val_accuracy: 0.1903 - val_loss: 2.5363 - learning_rate: 1.2500e-04\n","Epoch 15/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.5488 - loss: 1.1434 - val_accuracy: 0.1835 - val_loss: 2.6116 - learning_rate: 6.2500e-05\n","Epoch 16/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.5556 - loss: 1.1427 - val_accuracy: 0.1780 - val_loss: 2.7700 - learning_rate: 3.1250e-05\n","Epoch 17/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.5656 - loss: 1.1237 - val_accuracy: 0.1747 - val_loss: 2.7649 - learning_rate: 1.5625e-05\n","Epoch 18/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 85ms/step - accuracy: 0.5589 - loss: 1.1302 - val_accuracy: 0.1817 - val_loss: 2.7348 - learning_rate: 7.8125e-06\n","Epoch 19/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 85ms/step - accuracy: 0.5573 - loss: 1.1322 - val_accuracy: 0.1785 - val_loss: 2.7499 - learning_rate: 3.9063e-06\n","Epoch 20/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.5584 - loss: 1.1345 - val_accuracy: 0.1773 - val_loss: 2.7533 - learning_rate: 1.9531e-06\n","Epoch 21/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.5565 - loss: 1.1420 - val_accuracy: 0.1776 - val_loss: 2.7371 - learning_rate: 9.7656e-07\n","Epoch 22/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 85ms/step - accuracy: 0.5575 - loss: 1.1334 - val_accuracy: 0.1797 - val_loss: 2.7541 - learning_rate: 4.8828e-07\n","Epoch 23/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.5581 - loss: 1.1253 - val_accuracy: 0.1759 - val_loss: 2.7548 - learning_rate: 2.4414e-07\n","Epoch 24/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.5666 - loss: 1.1202 - val_accuracy: 0.1778 - val_loss: 2.7507 - learning_rate: 1.2207e-07\n","Epoch 25/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 87ms/step - accuracy: 0.5514 - loss: 1.1390 - val_accuracy: 0.1763 - val_loss: 2.7519 - learning_rate: 6.1035e-08\n","Epoch 26/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.5567 - loss: 1.1399 - val_accuracy: 0.1792 - val_loss: 2.7662 - learning_rate: 3.0518e-08\n","Epoch 27/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 86ms/step - accuracy: 0.5542 - loss: 1.1347 - val_accuracy: 0.1787 - val_loss: 2.7432 - learning_rate: 1.5259e-08\n","Epoch 28/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 84ms/step - accuracy: 0.5573 - loss: 1.1311 - val_accuracy: 0.1816 - val_loss: 2.7628 - learning_rate: 7.6294e-09\n","Epoch 29/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 84ms/step - accuracy: 0.5494 - loss: 1.1382 - val_accuracy: 0.1769 - val_loss: 2.8159 - learning_rate: 3.8147e-09\n","Epoch 30/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 84ms/step - accuracy: 0.5602 - loss: 1.1272 - val_accuracy: 0.1800 - val_loss: 2.7251 - learning_rate: 1.9073e-09\n","Epoch 31/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 83ms/step - accuracy: 0.5623 - loss: 1.1204 - val_accuracy: 0.1814 - val_loss: 2.7443 - learning_rate: 9.5367e-10\n","Epoch 32/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 83ms/step - accuracy: 0.5515 - loss: 1.1336 - val_accuracy: 0.1756 - val_loss: 2.7885 - learning_rate: 4.7684e-10\n","Epoch 33/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 84ms/step - accuracy: 0.5599 - loss: 1.1324 - val_accuracy: 0.1802 - val_loss: 2.7327 - learning_rate: 2.3842e-10\n","Epoch 34/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 84ms/step - accuracy: 0.5665 - loss: 1.1199 - val_accuracy: 0.1807 - val_loss: 2.7381 - learning_rate: 1.1921e-10\n","Epoch 35/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 84ms/step - accuracy: 0.5566 - loss: 1.1382 - val_accuracy: 0.1795 - val_loss: 2.7471 - learning_rate: 5.9605e-11\n","Epoch 36/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 84ms/step - accuracy: 0.5625 - loss: 1.1265 - val_accuracy: 0.1769 - val_loss: 2.7528 - learning_rate: 2.9802e-11\n","Epoch 37/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 84ms/step - accuracy: 0.5609 - loss: 1.1301 - val_accuracy: 0.1824 - val_loss: 2.7558 - learning_rate: 1.4901e-11\n","Epoch 38/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 82ms/step - accuracy: 0.5565 - loss: 1.1371 - val_accuracy: 0.1775 - val_loss: 2.7090 - learning_rate: 7.4506e-12\n","Epoch 39/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 81ms/step - accuracy: 0.5638 - loss: 1.1227 - val_accuracy: 0.1819 - val_loss: 2.7220 - learning_rate: 3.7253e-12\n","Epoch 40/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 81ms/step - accuracy: 0.5562 - loss: 1.1363 - val_accuracy: 0.1768 - val_loss: 2.7734 - learning_rate: 1.8626e-12\n","Epoch 41/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 79ms/step - accuracy: 0.5601 - loss: 1.1304 - val_accuracy: 0.1792 - val_loss: 2.7584 - learning_rate: 9.3132e-13\n","Epoch 42/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 76ms/step - accuracy: 0.5599 - loss: 1.1316 - val_accuracy: 0.1804 - val_loss: 2.7411 - learning_rate: 4.6566e-13\n","Epoch 43/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 79ms/step - accuracy: 0.5522 - loss: 1.1428 - val_accuracy: 0.1805 - val_loss: 2.7582 - learning_rate: 2.3283e-13\n","Epoch 44/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 79ms/step - accuracy: 0.5520 - loss: 1.1392 - val_accuracy: 0.1793 - val_loss: 2.7511 - learning_rate: 1.1642e-13\n","Epoch 45/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 78ms/step - accuracy: 0.5536 - loss: 1.1370 - val_accuracy: 0.1790 - val_loss: 2.7540 - learning_rate: 5.8208e-14\n","Epoch 46/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 85ms/step - accuracy: 0.5632 - loss: 1.1255 - val_accuracy: 0.1828 - val_loss: 2.7194 - learning_rate: 2.9104e-14\n","Epoch 47/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 79ms/step - accuracy: 0.5573 - loss: 1.1303 - val_accuracy: 0.1812 - val_loss: 2.7514 - learning_rate: 1.4552e-14\n","Epoch 48/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 78ms/step - accuracy: 0.5626 - loss: 1.1245 - val_accuracy: 0.1756 - val_loss: 2.8072 - learning_rate: 7.2760e-15\n","Epoch 49/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 78ms/step - accuracy: 0.5597 - loss: 1.1348 - val_accuracy: 0.1800 - val_loss: 2.7388 - learning_rate: 3.6380e-15\n","Epoch 50/50\n","\u001b[1m730/730\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 78ms/step - accuracy: 0.5564 - loss: 1.1368 - val_accuracy: 0.1768 - val_loss: 2.7820 - learning_rate: 1.8190e-15\n"]}],"source":["def scheduler(epoch, lr):\n","    if epoch > 10:  # Reduce learning rate after 10 epochs\n","        lr = lr * 0.5\n","    return lr\n","lr_scheduler = LearningRateScheduler(scheduler)\n","history = model.fit(x_train, y_train, \n","                    validation_data=(x_val, y_val),\n","                    epochs=50, batch_size=32, \n","                    callbacks=[lr_scheduler])"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["keras.saving.save_model(model=model, filepath=\"../api/utils/speech_recognition_model.keras\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyM3hq5PpRjL/JCO/NAE9fA0","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.6"}},"nbformat":4,"nbformat_minor":0}
